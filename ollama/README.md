# Ollama

## Demo

```shell
# launch the server
ollama serve

# run a model
ollama run llama3
```
